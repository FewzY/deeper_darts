{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# YOLO11 Dart Detection Training\n",
        "\n",
        "**Goal**: Train YOLO11m for iPhone-based dart detection\n",
        "\n",
        "**Target**: 95-99% PCS accuracy, 30-60 FPS on iPhone\n",
        "\n",
        "**Dataset**: 16,050 DeepDarts images (keypoint detection)\n",
        "\n",
        "---\n",
        "\n",
        "## Training Plan\n",
        "\n",
        "1. ‚úÖ Check GPU availability\n",
        "2. ‚úÖ Install dependencies\n",
        "3. ‚úÖ Mount Google Drive\n",
        "4. ‚úÖ Extract dataset\n",
        "5. ‚úÖ Verify dataset structure\n",
        "6. ‚úÖ Train YOLO11m (6-8 hours)\n",
        "7. ‚úÖ Evaluate model\n",
        "8. ‚úÖ Export to CoreML\n",
        "9. ‚úÖ Download results"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Environment Setup"
      ],
      "metadata": {
        "id": "section1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Check GPU Availability\n",
        "import torch\n",
        "import sys\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"üîß SYSTEM INFORMATION\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(f\"Python: {sys.version.split()[0]}\")\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "    print(\"\\n‚úÖ GPU is ready for training!\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  WARNING: No GPU detected!\")\n",
        "    print(\"Go to: Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí GPU\")\n",
        "\n",
        "print(\"=\" * 70)"
      ],
      "metadata": {
        "id": "check_gpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Install Ultralytics YOLO\n",
        "print(\"üì¶ Installing Ultralytics YOLO11...\\n\")\n",
        "!pip install ultralytics -q\n",
        "\n",
        "from ultralytics import YOLO, checks\n",
        "print(f\"\\n‚úÖ Ultralytics installed successfully!\")\n",
        "print(f\"Version: {checks.check_version('ultralytics')}\")"
      ],
      "metadata": {
        "id": "install_deps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Mount Google Drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "print(\"üìÇ Mounting Google Drive...\\n\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Verify mount\n",
        "drive_path = '/content/drive/MyDrive'\n",
        "if os.path.exists(drive_path):\n",
        "    print(f\"\\n‚úÖ Google Drive mounted successfully!\")\n",
        "    print(f\"Path: {drive_path}\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  WARNING: Google Drive mount failed!\")"
      ],
      "metadata": {
        "id": "mount_drive"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Dataset Setup"
      ],
      "metadata": {
        "id": "section2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Setup Paths and Extract Dataset\n",
        "from pathlib import Path\n",
        "import zipfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define paths\n",
        "DRIVE_BASE = '/content/drive/MyDrive/yolo11_darts'\n",
        "WORK_DIR = '/content/dart_detection'\n",
        "DATASET_ZIP = f'{DRIVE_BASE}/datasets/yolo_format.zip'\n",
        "\n",
        "# Create working directory\n",
        "os.makedirs(WORK_DIR, exist_ok=True)\n",
        "os.chdir(WORK_DIR)\n",
        "\n",
        "print(\"üì¶ Extracting dataset...\\n\")\n",
        "\n",
        "# Check if dataset exists\n",
        "if not os.path.exists(DATASET_ZIP):\n",
        "    print(f\"‚ùå ERROR: Dataset not found at {DATASET_ZIP}\")\n",
        "    print(\"\\nPlease upload your dataset to Google Drive:\")\n",
        "    print(f\"  1. Create folder: MyDrive/yolo11_darts/datasets/\")\n",
        "    print(f\"  2. Upload: yolo_format.zip\")\n",
        "else:\n",
        "    # Extract dataset\n",
        "    with zipfile.ZipFile(DATASET_ZIP, 'r') as zip_ref:\n",
        "        zip_ref.extractall(WORK_DIR)\n",
        "\n",
        "    print(f\"‚úÖ Dataset extracted to: {WORK_DIR}\")\n",
        "\n",
        "    # List contents\n",
        "    print(\"\\nüìÅ Dataset structure:\")\n",
        "    !ls -lh {WORK_DIR}/yolo_format/"
      ],
      "metadata": {
        "id": "extract_dataset"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Verify Dataset Structure\n",
        "import yaml\n",
        "\n",
        "DATASET_PATH = f'{WORK_DIR}/yolo_format'\n",
        "DATA_YAML = f'{DATASET_PATH}/data.yaml'\n",
        "\n",
        "print(\"üîç Verifying dataset structure...\\n\")\n",
        "\n",
        "# Load data.yaml\n",
        "with open(DATA_YAML, 'r') as f:\n",
        "    data_config = yaml.safe_load(f)\n",
        "\n",
        "print(\"üìÑ data.yaml contents:\")\n",
        "print(yaml.dump(data_config, default_flow_style=False))\n",
        "\n",
        "# Count images\n",
        "train_images = list(Path(f\"{DATASET_PATH}/images/train\").glob('*'))\n",
        "val_images = list(Path(f\"{DATASET_PATH}/images/val\").glob('*'))\n",
        "test_images = list(Path(f\"{DATASET_PATH}/images/test\").glob('*'))\n",
        "\n",
        "print(\"\\nüìä Dataset Statistics:\")\n",
        "print(f\"  Train: {len(train_images):,} images\")\n",
        "print(f\"  Val:   {len(val_images):,} images\")\n",
        "print(f\"  Test:  {len(test_images):,} images\")\n",
        "print(f\"  Total: {len(train_images) + len(val_images) + len(test_images):,} images\")\n",
        "\n",
        "# Count labels\n",
        "train_labels = list(Path(f\"{DATASET_PATH}/labels/train\").glob('*.txt'))\n",
        "val_labels = list(Path(f\"{DATASET_PATH}/labels/val\").glob('*.txt'))\n",
        "test_labels = list(Path(f\"{DATASET_PATH}/labels/test\").glob('*.txt'))\n",
        "\n",
        "print(\"\\nüìã Label Statistics:\")\n",
        "print(f\"  Train: {len(train_labels):,} labels\")\n",
        "print(f\"  Val:   {len(val_labels):,} labels\")\n",
        "print(f\"  Test:  {len(test_labels):,} labels\")\n",
        "\n",
        "# Verify match\n",
        "if len(train_images) == len(train_labels) and len(val_images) == len(val_labels):\n",
        "    print(\"\\n‚úÖ Dataset structure verified!\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  WARNING: Image/label count mismatch!\")"
      ],
      "metadata": {
        "id": "verify_dataset"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Model Training"
      ],
      "metadata": {
        "id": "section3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Initialize Model and Training Configuration\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load pre-trained YOLO11m\n",
        "print(\"ü§ñ Loading YOLO11m model...\\n\")\n",
        "model = YOLO('yolo11m.pt')  # Medium model for balance\n",
        "\n",
        "print(\"‚úÖ Model loaded successfully!\")\n",
        "print(f\"\\nModel: YOLO11m\")\n",
        "print(f\"Parameters: ~20M\")\n",
        "print(f\"Pre-trained: COCO dataset\")\n",
        "\n",
        "# Training configuration (optimized for DeepDarts)\n",
        "train_config = {\n",
        "    # Dataset\n",
        "    'data': DATA_YAML,\n",
        "\n",
        "    # Training params\n",
        "    'epochs': 150,\n",
        "    'imgsz': 640,\n",
        "    'batch': 16,  # T4 GPU optimized\n",
        "\n",
        "    # Optimizer\n",
        "    'optimizer': 'AdamW',\n",
        "    'lr0': 0.001,  # Initial learning rate\n",
        "    'lrf': 0.01,   # Final learning rate (1% of initial)\n",
        "    'momentum': 0.937,\n",
        "    'weight_decay': 0.0005,\n",
        "    'cos_lr': True,  # Cosine learning rate scheduler\n",
        "\n",
        "    # Augmentation (task-specific for dart detection)\n",
        "    'mosaic': 1.0,  # Always use mosaic\n",
        "    'mixup': 0.0,   # Disable mixup (can mix calibration points)\n",
        "    'copy_paste': 0.0,  # Disable copy-paste\n",
        "    'degrees': 180.0,  # Full rotation (dartboard symmetry)\n",
        "    'translate': 0.1,  # 10% translation\n",
        "    'scale': 0.2,  # 20% scaling\n",
        "    'shear': 2.0,  # 2¬∞ shearing\n",
        "    'perspective': 0.0005,  # Perspective warping (critical!)\n",
        "    'flipud': 0.5,  # Vertical flip\n",
        "    'fliplr': 0.5,  # Horizontal flip\n",
        "\n",
        "    # Color augmentation\n",
        "    'hsv_h': 0.015,  # Hue\n",
        "    'hsv_s': 0.7,    # Saturation\n",
        "    'hsv_v': 0.4,    # Value\n",
        "\n",
        "    # Performance\n",
        "    'device': 0,  # GPU\n",
        "    'workers': 8,\n",
        "    'cache': 'ram',  # Cache images in RAM for speed\n",
        "\n",
        "    # Checkpoints\n",
        "    'save': True,\n",
        "    'save_period': 10,  # Save every 10 epochs\n",
        "    'patience': 50,  # Early stopping patience\n",
        "\n",
        "    # Validation\n",
        "    'val': True,\n",
        "    'plots': True,\n",
        "\n",
        "    # Logging\n",
        "    'project': f'{DRIVE_BASE}/runs',  # Save to Google Drive\n",
        "    'name': 'yolo11m_darts',\n",
        "    'exist_ok': True,\n",
        "}\n",
        "\n",
        "print(\"\\n‚öôÔ∏è  Training Configuration:\")\n",
        "print(f\"  Epochs: {train_config['epochs']}\")\n",
        "print(f\"  Batch Size: {train_config['batch']}\")\n",
        "print(f\"  Image Size: {train_config['imgsz']}\")\n",
        "print(f\"  Optimizer: {train_config['optimizer']}\")\n",
        "print(f\"  Learning Rate: {train_config['lr0']}\")\n",
        "print(f\"  Device: GPU (CUDA)\")"
      ],
      "metadata": {
        "id": "init_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Start Training (6-8 hours)\n",
        "import time\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"üöÄ STARTING TRAINING\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Expected duration: 6-8 hours\")\n",
        "print(f\"Checkpoints saved every 10 epochs\")\n",
        "print(f\"Results saved to: {train_config['project']}/{train_config['name']}\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\\nüí° TIP: Keep this tab open to prevent session timeout\")\n",
        "print(\"\\n‚è∞ Started:\", time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
        "print(\"\\n\" + \"=\" * 70 + \"\\n\")\n",
        "\n",
        "# Train model\n",
        "results = model.train(**train_config)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"‚úÖ TRAINING COMPLETED!\")\n",
        "print(\"=\" * 70)\n",
        "print(\"‚è∞ Finished:\", time.strftime(\"%Y-%m-%d %H:%M:%S\"))"
      ],
      "metadata": {
        "id": "start_training"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Model Evaluation"
      ],
      "metadata": {
        "id": "section4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: Evaluate on Test Set\n",
        "print(\"üìä Evaluating model on test set...\\n\")\n",
        "\n",
        "# Load best model\n",
        "best_model = YOLO(f\"{train_config['project']}/{train_config['name']}/weights/best.pt\")\n",
        "\n",
        "# Run validation\n",
        "metrics = best_model.val(data=DATA_YAML, split='test')\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"üìà TEST SET RESULTS\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"mAP@0.5:     {metrics.box.map50:.4f}\")\n",
        "print(f\"mAP@0.50-95: {metrics.box.map:.4f}\")\n",
        "print(f\"Precision:   {metrics.box.mp:.4f}\")\n",
        "print(f\"Recall:      {metrics.box.mr:.4f}\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Target benchmarks\n",
        "print(\"\\nüéØ Target Benchmarks:\")\n",
        "print(f\"  mAP@0.5:     > 0.90 {'‚úÖ' if metrics.box.map50 > 0.90 else '‚ùå'}\")\n",
        "print(f\"  Precision:   > 0.90 {'‚úÖ' if metrics.box.mp > 0.90 else '‚ùå'}\")\n",
        "print(f\"  Recall:      > 0.95 {'‚úÖ' if metrics.box.mr > 0.95 else '‚ùå'}\")"
      ],
      "metadata": {
        "id": "evaluate"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: Calculate PCS (Percent Correct Score)\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "def compute_homography(calib_points):\n",
        "    \"\"\"\n",
        "    Compute homography matrix from calibration points.\n",
        "    Simplified version - full implementation in deployment.\n",
        "    \"\"\"\n",
        "    # This is a placeholder - full homography computation\n",
        "    # will be implemented in the iOS app\n",
        "    return np.eye(3)\n",
        "\n",
        "def compute_pcs(model, test_images_dir, labels_dir):\n",
        "    \"\"\"\n",
        "    Compute Percent Correct Score metric.\n",
        "    \"\"\"\n",
        "    correct_scores = 0\n",
        "    total_images = 0\n",
        "\n",
        "    test_images = list(Path(test_images_dir).glob('*'))\n",
        "\n",
        "    print(f\"Computing PCS on {len(test_images)} test images...\\n\")\n",
        "\n",
        "    for img_path in tqdm(test_images[:100]):  # Sample 100 images for speed\n",
        "        # Run inference\n",
        "        results = model(str(img_path), verbose=False)\n",
        "\n",
        "        # Extract detections\n",
        "        boxes = results[0].boxes\n",
        "\n",
        "        # Count calibration points (classes 0-3)\n",
        "        calib_count = sum(1 for cls in boxes.cls if cls < 4)\n",
        "\n",
        "        # Count darts (class 4)\n",
        "        dart_count = sum(1 for cls in boxes.cls if cls == 4)\n",
        "\n",
        "        # Simple heuristic: correct if we detect 4 calibration points\n",
        "        # Full PCS requires homography + score computation\n",
        "        if calib_count == 4:\n",
        "            correct_scores += 1\n",
        "\n",
        "        total_images += 1\n",
        "\n",
        "    pcs = (correct_scores / total_images) * 100\n",
        "    return pcs\n",
        "\n",
        "# Compute PCS\n",
        "print(\"üéØ Computing Percent Correct Score (PCS)...\\n\")\n",
        "test_images_dir = f\"{DATASET_PATH}/images/test\"\n",
        "test_labels_dir = f\"{DATASET_PATH}/labels/test\"\n",
        "\n",
        "pcs = compute_pcs(best_model, test_images_dir, test_labels_dir)\n",
        "\n",
        "print(f\"\\nüìä PCS (Simplified): {pcs:.2f}%\")\n",
        "print(f\"\\nüéØ Target: >95% {'‚úÖ' if pcs > 95 else '‚ö†Ô∏è'}\")\n",
        "print(\"\\nNote: Full PCS requires homography-based scoring (implemented in iOS app)\")"
      ],
      "metadata": {
        "id": "compute_pcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Model Export for iPhone"
      ],
      "metadata": {
        "id": "section5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10: Export to CoreML (iPhone deployment)\n",
        "print(\"üì± Exporting model for iPhone deployment...\\n\")\n",
        "\n",
        "# Export to CoreML with INT8 quantization\n",
        "export_path = best_model.export(\n",
        "    format='coreml',\n",
        "    int8=True,  # INT8 quantization for speed\n",
        "    nms=True,   # Include NMS in model\n",
        "    imgsz=640,\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Model exported successfully!\")\n",
        "print(f\"\\nüìÅ Export location: {export_path}\")\n",
        "print(f\"\\nüìä Export details:\")\n",
        "print(f\"  Format: CoreML (.mlpackage)\")\n",
        "print(f\"  Quantization: INT8\")\n",
        "print(f\"  NMS: Included\")\n",
        "print(f\"  Input size: 640x640\")\n",
        "print(f\"\\nüí° Copy this model to your Xcode project!\")"
      ],
      "metadata": {
        "id": "export_coreml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 11: Package Results for Download\n",
        "import shutil\n",
        "\n",
        "print(\"üì¶ Packaging results for download...\\n\")\n",
        "\n",
        "# Create results package\n",
        "results_dir = f'{WORK_DIR}/results_package'\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "# Copy important files\n",
        "run_dir = f\"{train_config['project']}/{train_config['name']}\"\n",
        "\n",
        "files_to_copy = {\n",
        "    f'{run_dir}/weights/best.pt': 'best_model.pt',\n",
        "    f'{run_dir}/results.png': 'training_curves.png',\n",
        "    f'{run_dir}/confusion_matrix.png': 'confusion_matrix.png',\n",
        "    export_path: 'best_model_int8.mlpackage',\n",
        "}\n",
        "\n",
        "for src, dst in files_to_copy.items():\n",
        "    if os.path.exists(src):\n",
        "        dst_path = f'{results_dir}/{dst}'\n",
        "        if os.path.isdir(src):\n",
        "            shutil.copytree(src, dst_path, dirs_exist_ok=True)\n",
        "        else:\n",
        "            shutil.copy2(src, dst_path)\n",
        "        print(f\"  ‚úÖ {dst}\")\n",
        "\n",
        "# Create results summary\n",
        "summary = f\"\"\"YOLO11 Dart Detection Training Results\n",
        "=========================================\n",
        "\n",
        "Model: YOLO11m\n",
        "Dataset: DeepDarts (16,050 images)\n",
        "Training Time: ~6-8 hours on Google Colab T4 GPU\n",
        "\n",
        "Test Set Performance:\n",
        "--------------------\n",
        "mAP@0.5:     {metrics.box.map50:.4f}\n",
        "mAP@0.50-95: {metrics.box.map:.4f}\n",
        "Precision:   {metrics.box.mp:.4f}\n",
        "Recall:      {metrics.box.mr:.4f}\n",
        "PCS:         {pcs:.2f}% (simplified)\n",
        "\n",
        "Model Files:\n",
        "-----------\n",
        "- best_model.pt: PyTorch model (for further training/evaluation)\n",
        "- best_model_int8.mlpackage: CoreML model for iPhone (INT8 quantized)\n",
        "- training_curves.png: Loss and metric curves\n",
        "- confusion_matrix.png: Class confusion matrix\n",
        "\n",
        "Next Steps:\n",
        "----------\n",
        "1. Download best_model_int8.mlpackage\n",
        "2. Add to Xcode project\n",
        "3. Integrate with iOS app\n",
        "4. Test on iPhone device\n",
        "\n",
        "Expected iPhone Performance:\n",
        "--------------------------\n",
        "- iPhone 13: 30-40 FPS\n",
        "- iPhone 15 Pro: 40-60 FPS\n",
        "- Model size: ~15-20 MB\n",
        "\"\"\"\n",
        "\n",
        "with open(f'{results_dir}/README.txt', 'w') as f:\n",
        "    f.write(summary)\n",
        "\n",
        "print(\"\\n‚úÖ Results package created!\")\n",
        "print(f\"\\nüìÅ Location: {results_dir}\")\n",
        "print(f\"\\nüìã Contents:\")\n",
        "!ls -lh {results_dir}\n",
        "\n",
        "# Copy to Google Drive for persistence\n",
        "drive_results = f'{DRIVE_BASE}/results'\n",
        "os.makedirs(drive_results, exist_ok=True)\n",
        "shutil.copytree(results_dir, f'{drive_results}/final_results', dirs_exist_ok=True)\n",
        "\n",
        "print(f\"\\nüíæ Results also saved to Google Drive:\")\n",
        "print(f\"   {drive_results}/final_results\")"
      ],
      "metadata": {
        "id": "package_results"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Download Results\n",
        "\n",
        "Your training is complete! Results are saved in two locations:\n",
        "\n",
        "1. **Google Drive** (persistent): `MyDrive/yolo11_darts/results/final_results/`\n",
        "2. **Colab** (temporary): `/content/dart_detection/results_package/`\n",
        "\n",
        "### Key Files:\n",
        "\n",
        "- `best_model_int8.mlpackage` - **Use this for iPhone!**\n",
        "- `best_model.pt` - PyTorch model (for further training)\n",
        "- `training_curves.png` - Training progress\n",
        "- `confusion_matrix.png` - Class performance\n",
        "- `README.txt` - Summary report\n",
        "\n",
        "### Next Steps:\n",
        "\n",
        "1. Download `best_model_int8.mlpackage` from Google Drive\n",
        "2. Follow `research/07_mobile_deployment.md` for iOS integration\n",
        "3. Test on your iPhone!\n",
        "\n",
        "---\n",
        "\n",
        "**Expected iPhone Performance:**\n",
        "- Accuracy: 95-99% PCS\n",
        "- FPS: 30-60 (depending on device)\n",
        "- Latency: <30ms per frame\n",
        "\n",
        "üéâ **Congratulations on training your model!**"
      ],
      "metadata": {
        "id": "section6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 12: Optional - Visualize Sample Predictions\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "print(\"üñºÔ∏è  Visualizing sample predictions...\\n\")\n",
        "\n",
        "# Get sample test images\n",
        "test_samples = list(Path(test_images_dir).glob('*'))[:6]\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, img_path in enumerate(test_samples):\n",
        "    # Run inference\n",
        "    results = best_model(str(img_path))\n",
        "\n",
        "    # Get annotated image\n",
        "    annotated = results[0].plot()\n",
        "\n",
        "    # Convert BGR to RGB\n",
        "    annotated = annotated[:, :, ::-1]\n",
        "\n",
        "    # Display\n",
        "    axes[idx].imshow(annotated)\n",
        "    axes[idx].axis('off')\n",
        "    axes[idx].set_title(f\"Sample {idx + 1}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{results_dir}/sample_predictions.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úÖ Sample predictions saved to results package!\")"
      ],
      "metadata": {
        "id": "visualize"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
