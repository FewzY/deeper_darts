                  epoch,         train/box_loss,         train/cls_loss,         train/dfl_loss,   metrics/precision(B),      metrics/recall(B),       metrics/mAP50(B),    metrics/mAP50-95(B),           val/box_loss,           val/cls_loss,           val/dfl_loss,                 lr/pg0,                 lr/pg1,                 lr/pg2
                      1,                 1.8957,                 2.9516,                 1.0597,                0.76743,                0.83116,                0.83733,                0.58862,                 1.0416,                 19.141,                0.78027,               0.067021,             0.00033312,             0.00033312
                      2,                 1.1386,                0.91813,                0.87216,                0.83733,                0.90524,                0.88658,                0.65232,                  0.924,                 28.443,                0.75986,               0.034021,             0.00066629,             0.00066629
                      3,                 1.0597,                0.77296,                0.85497,                0.85852,                0.93152,                0.90158,                0.66985,                0.88478,                 28.043,                0.74924,              0.0010202,             0.00099881,             0.00099881
                      4,                 1.0055,                0.69554,                0.84418,                0.86819,                0.95401,                0.88106,                0.65508,                 0.8695,                 42.495,                0.74512,              0.0009978,              0.0009978,              0.0009978
                      5,                0.95725,                0.64541,                0.83572,                0.87461,                0.95775,                0.89011,                0.66023,                0.86377,                 40.135,                 0.7412,              0.0009978,              0.0009978,              0.0009978
                      6,                0.92611,                0.60349,                0.83086,                 0.8748,                0.96481,                0.88192,                0.65103,                0.86736,                 48.256,                0.74128,              0.0009961,              0.0009961,              0.0009961
                      7,                0.90544,                0.57619,                 0.8265,                0.87654,                0.96679,                0.88717,                0.67321,                0.81406,                  50.02,                0.73484,             0.00099391,             0.00099391,             0.00099391
                      8,                0.88784,                0.55509,                0.82526,                0.87684,                0.97017,                0.88189,                0.68071,                0.78194,                 52.467,                0.73223,             0.00099123,             0.00099123,             0.00099123
                      9,                 0.8754,                0.53898,                0.82302,                0.87433,                0.97258,                0.88165,                0.68154,                0.78838,                 53.638,                0.73262,             0.00098808,             0.00098808,             0.00098808
                     10,                0.86679,                  0.527,                0.82099,                0.87791,                0.97387,                0.88704,                0.68561,                0.80672,                 51.828,                0.73417,             0.00098445,             0.00098445,             0.00098445
                     11,                0.85309,                0.51307,                0.81988,                0.87666,                0.97648,                0.88752,                0.68489,                0.79143,                 52.533,                0.73151,             0.00098035,             0.00098035,             0.00098035
